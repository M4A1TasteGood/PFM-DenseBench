<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PFM-DenseBench | 病理基础模型密集预测基准测试</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Noto+Sans+SC:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <!-- 导航栏 -->
    <nav class="navbar">
        <div class="nav-container">
            <a href="#" class="nav-logo">PFM-DenseBench</a>
            <ul class="nav-menu">
                <li><a href="#abstract">摘要</a></li>
                <li><a href="#research-questions">研究问题</a></li>
                <li><a href="#benchmark">基准设计</a></li>
                <li><a href="#findings">主要发现</a></li>
                <li><a href="#results">实验结果</a></li>
                <li><a href="#appendix">附录</a></li>
            </ul>
            <button class="nav-toggle" aria-label="Toggle menu">
                <span></span>
                <span></span>
                <span></span>
            </button>
        </div>
    </nav>

    <!-- 主横幅 -->
    <header class="hero">
        <div class="hero-content">
            <h1 class="hero-title">
                To What Extent Do Token-Level Representations from Pathology Foundation Models Improve Dense Prediction?
            </h1>
            <p class="hero-subtitle">
                病理基础模型的Token级表征在多大程度上改善密集预测？
            </p>
            <div class="hero-authors">
                <p>
                    Weiming Chen<sup>*1</sup>, Xitong Ling<sup>*1</sup>, Xidong Wang<sup>2</sup>, Zhenyang Cai<sup>2</sup>, 
                    Yijia Guo<sup>3</sup>, Mingxi Fu<sup>1</sup>, Ziyi Zeng<sup>2</sup>, Minxi Ouyang<sup>1</sup>, 
                    Jiawen Li<sup>1</sup>, Yizhi Wang<sup>1</sup>, Tian Guan<sup>1</sup>, 
                    Benyou Wang<sup>#2</sup>, Yonghong He<sup>#1</sup>
                </p>
                <p class="affiliations">
                    <sup>1</sup>清华大学深圳国际研究生院 &nbsp;&nbsp;
                    <sup>2</sup>香港中文大学（深圳）&nbsp;&nbsp;
                    <sup>3</sup>北京大学
                </p>
            </div>
            <div class="hero-venue">
                <span class="venue-badge">ICML 2025</span>
                <span class="venue-location">Vancouver, Canada</span>
            </div>
            <div class="hero-links">
                <a href="#" class="btn btn-primary">
                    <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>
                    论文 PDF
                </a>
                <a href="#" class="btn btn-secondary">
                    <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg>
                    代码
                </a>
                <a href="#" class="btn btn-secondary">
                    <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><ellipse cx="12" cy="5" rx="9" ry="3"></ellipse><path d="M21 12c0 1.66-4 3-9 3s-9-1.34-9-3"></path><path d="M3 5v14c0 1.66 4 3 9 3s9-1.34 9-3V5"></path></svg>
                    数据集
                </a>
            </div>
        </div>
        <div class="hero-visual">
            <div class="hero-image-placeholder">
                <p>论文概览图</p>
                <small>Figure 1: PFM-DenseBench 框架总览</small>
            </div>
        </div>
    </header>

    <!-- 摘要 -->
    <section id="abstract" class="section">
        <div class="container">
            <h2 class="section-title">摘要</h2>
            <div class="abstract-content">
                <p>
                    <strong>病理基础模型（Pathology Foundation Models, PFMs）</strong>已经快速发展，正在成为下游临床任务的通用主干网络，
                    在不同组织和机构之间展现出强大的迁移能力。然而，对于<strong>密集预测任务</strong>（如分割），
                    实际部署中仍然缺乏清晰、可复现的理解——关于不同PFM在各数据集上的行为表现，
                    以及适配策略选择如何影响性能和稳定性。
                </p>
                <p>
                    我们提出了<strong>PFM-DenseBench</strong>——一个大规模的病理密集预测基准测试，
                    评估了<span class="highlight">17个PFM</span>在<span class="highlight">18个公开分割数据集</span>上的表现。
                    在统一的协议下，我们系统地评估了PFM的多种适配和微调策略，
                    得出了具有洞察力的、面向实践的发现——关于不同PFM和调优选择何时以及为何在异构数据集上成功或失败。
                </p>
                <p>
                    我们发布了容器、配置文件和数据集卡，以支持可复现的评估和真实世界密集病理任务中的明智PFM选择。
                </p>
            </div>
            <div class="stats-grid">
                <div class="stat-card">
                    <span class="stat-number">17</span>
                    <span class="stat-label">病理基础模型</span>
                </div>
                <div class="stat-card">
                    <span class="stat-number">18</span>
                    <span class="stat-label">分割数据集</span>
                </div>
                <div class="stat-card">
                    <span class="stat-number">5</span>
                    <span class="stat-label">微调策略</span>
                </div>
                <div class="stat-card">
                    <span class="stat-number">8</span>
                    <span class="stat-label">评估指标</span>
                </div>
            </div>
        </div>
    </section>

    <!-- 研究问题 -->
    <section id="research-questions" class="section section-alt">
        <div class="container">
            <h2 class="section-title">核心研究问题</h2>
            <p class="section-intro">
                本研究旨在严格审视基础模型向密集预测任务的迁移能力，通过回答四个基本研究问题：
            </p>
            <div class="rq-grid">
                <div class="rq-card">
                    <div class="rq-header">
                        <span class="rq-badge">RQ1</span>
                        <h3>可行性与性能提升</h3>
                    </div>
                    <p>
                        PFM能否在密集预测中实现与分类任务中观察到的相同幅度的性能提升？
                        具体而言，预训练表征是否比强大的任务特定监督基线（如UNet）具有显著优势？
                    </p>
                </div>
                <div class="rq-card">
                    <div class="rq-header">
                        <span class="rq-badge">RQ2</span>
                        <h3>粒度依赖的泛化</h3>
                    </div>
                    <p>
                        PFM的迁移能力是否因生物尺度而异？我们假设针对切片级语义优化的表征，
                        在迁移到细胞核级（微观）、腺体级（介观）和组织级（宏观）分割时可能表现不同。
                    </p>
                </div>
                <div class="rq-card">
                    <div class="rq-header">
                        <span class="rq-badge">RQ3</span>
                        <h3>密集预测的缩放定律</h3>
                    </div>
                    <p>
                        预训练数据量、模型参数规模和适配容量（如LoRA秩）等因素如何影响下游性能？
                        我们探究缩放定律是否适用于密集病理任务，或者当需要精确定位时性能是否会以不同方式饱和。
                    </p>
                </div>
                <div class="rq-card">
                    <div class="rq-header">
                        <span class="rq-badge">RQ4</span>
                        <h3>架构归纳偏置</h3>
                    </div>
                    <p>
                        纯Vision Transformer（ViT）范式对于密集预测是否是最优的？
                        考虑到分割依赖于局部纹理和边界线索，我们研究通过混合适配器注入卷积归纳偏置是否能提供更优性能。
                    </p>
                </div>
            </div>
        </div>
    </section>

    <!-- 基准设计 -->
    <section id="benchmark" class="section">
        <div class="container">
            <h2 class="section-title">基准设计</h2>
            
            <!-- 数据集 -->
            <div class="subsection">
                <h3 class="subsection-title">数据集</h3>
                <p class="subsection-intro">
                    我们在PathSeg基准测试的标准化套件中评估PFM表征的泛化能力，该套件包含18个分割数据集，
                    旨在沿三个关键轴探测性能：
                </p>
                <div class="feature-grid">
                    <div class="feature-card">
                        <div class="feature-icon">🏥</div>
                        <h4>多样化器官系统</h4>
                        <p>涵盖乳腺（BCSS, TNBC, NuCLS）、结肠（CONIC2022, GlaS, Lizard）、肺（WSSS4LUAD）、前列腺（RINGS）以及多器官数据集</p>
                    </div>
                    <div class="feature-card">
                        <div class="feature-icon">🔬</div>
                        <h4>多样癌症和组织类型</h4>
                        <p>包括腺癌、三阴性乳腺癌等侵袭性亚型，以及从正常和恶性上皮到炎症细胞和肿瘤相关基质的异质组织成分</p>
                    </div>
                    <div class="feature-card">
                        <div class="feature-icon">📏</div>
                        <h4>多尺度标注粒度</h4>
                        <p>任务分为细胞核级分割、腺体/结构级分割和区域级组织分割，实现从细胞到组织尺度的评估</p>
                    </div>
                </div>
                
                <div class="table-container">
                    <h4 class="table-title">表 A1. 数据集概览</h4>
                    <table class="data-table">
                        <thead>
                            <tr>
                                <th>数据集</th>
                                <th>放大倍率</th>
                                <th>解剖区域</th>
                                <th>分割级别</th>
                                <th>输入尺寸 (ViT-14/16)</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>BCSS</td>
                                <td>40x</td>
                                <td>乳腺</td>
                                <td>组织级</td>
                                <td>952 / 944</td>
                            </tr>
                            <tr>
                                <td>CoCaHis</td>
                                <td>40x</td>
                                <td>肝脏</td>
                                <td>组织级</td>
                                <td>994 / 992</td>
                            </tr>
                            <tr>
                                <td>CoNIC2022</td>
                                <td>20x</td>
                                <td>结肠</td>
                                <td>细胞核级</td>
                                <td>252 / 256</td>
                            </tr>
                            <tr>
                                <td>CoNSeP</td>
                                <td>40x</td>
                                <td>结肠</td>
                                <td>细胞核级</td>
                                <td>994 / 992</td>
                            </tr>
                            <tr>
                                <td>COSAS24</td>
                                <td>-</td>
                                <td>多器官</td>
                                <td>组织级</td>
                                <td>994 / 992</td>
                            </tr>
                            <tr>
                                <td>CPM15</td>
                                <td>20x, 40x</td>
                                <td>脑</td>
                                <td>细胞核级</td>
                                <td>392 / 384</td>
                            </tr>
                            <tr>
                                <td>CPM17</td>
                                <td>20x, 40x</td>
                                <td>多器官</td>
                                <td>细胞核级</td>
                                <td>490 / 496</td>
                            </tr>
                            <tr>
                                <td>CRAG</td>
                                <td>20x</td>
                                <td>结肠</td>
                                <td>腺体级</td>
                                <td>994 / 992</td>
                            </tr>
                            <tr>
                                <td>EBHI</td>
                                <td>40x</td>
                                <td>结肠</td>
                                <td>组织级</td>
                                <td>224 / 224</td>
                            </tr>
                            <tr>
                                <td>GlaS</td>
                                <td>20x</td>
                                <td>结肠</td>
                                <td>腺体级</td>
                                <td>420 / 416</td>
                            </tr>
                            <tr>
                                <td>Janowczyk</td>
                                <td>40x</td>
                                <td>乳腺</td>
                                <td>细胞核级</td>
                                <td>994 / 992</td>
                            </tr>
                            <tr>
                                <td>Kumar</td>
                                <td>40x</td>
                                <td>多器官</td>
                                <td>细胞核级</td>
                                <td>994 / 992</td>
                            </tr>
                            <tr>
                                <td>Lizard</td>
                                <td>20x</td>
                                <td>结肠</td>
                                <td>细胞核级</td>
                                <td>336 / 336</td>
                            </tr>
                            <tr>
                                <td>NuCLS</td>
                                <td>40x</td>
                                <td>乳腺</td>
                                <td>细胞核级</td>
                                <td>252 / 256</td>
                            </tr>
                            <tr>
                                <td>PanNuke</td>
                                <td>40x</td>
                                <td>多器官</td>
                                <td>细胞核级</td>
                                <td>252 / 256</td>
                            </tr>
                            <tr>
                                <td>RINGS</td>
                                <td>100x</td>
                                <td>前列腺</td>
                                <td>腺体级</td>
                                <td>994 / 992</td>
                            </tr>
                            <tr>
                                <td>TNBC</td>
                                <td>40x</td>
                                <td>乳腺</td>
                                <td>细胞核级</td>
                                <td>504 / 512</td>
                            </tr>
                            <tr>
                                <td>WSSS4LUAD</td>
                                <td>10x</td>
                                <td>肺</td>
                                <td>组织级</td>
                                <td>196 / 192</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>

            <!-- PFM模型 -->
            <div class="subsection">
                <h3 class="subsection-title">病理基础模型</h3>
                <p class="subsection-intro">
                    我们评估了17个最先进的病理基础模型，按预训练范式分为纯视觉模型和视觉-语言模型。
                </p>
                
                <div class="model-categories">
                    <div class="model-category">
                        <h4>纯视觉模型 (Vision-only PFMs)</h4>
                        <p class="category-desc">这些模型在大规模组织病理图像上预训练以学习视觉表征</p>
                        <div class="model-tags">
                            <span class="model-tag">UNI</span>
                            <span class="model-tag">UNI2-h</span>
                            <span class="model-tag">Virchow</span>
                            <span class="model-tag">Virchow2</span>
                            <span class="model-tag">Phikon</span>
                            <span class="model-tag">Phikon-v2</span>
                            <span class="model-tag">Prov-GigaPath</span>
                            <span class="model-tag">H-Optimus-0</span>
                            <span class="model-tag">H-Optimus-1</span>
                            <span class="model-tag">PathOrchestra</span>
                            <span class="model-tag">Midnight-12k</span>
                            <span class="model-tag">Kaiko</span>
                            <span class="model-tag">Lunit</span>
                            <span class="model-tag">Hibou</span>
                        </div>
                    </div>
                    <div class="model-category">
                        <h4>视觉-语言模型 (Vision-Language PFMs)</h4>
                        <p class="category-desc">这些模型融合文本监督以对齐视觉特征与病理语义</p>
                        <div class="model-tags">
                            <span class="model-tag vl">CONCH</span>
                            <span class="model-tag vl">CONCHv1.5</span>
                            <span class="model-tag vl">MUSK</span>
                        </div>
                    </div>
                </div>

                <div class="table-container">
                    <h4 class="table-title">表 B1. 病理基础模型概览</h4>
                    <table class="data-table model-table">
                        <thead>
                            <tr>
                                <th>模型</th>
                                <th>嵌入维度</th>
                                <th>切片数</th>
                                <th>参数量</th>
                                <th>架构</th>
                                <th>预训练策略</th>
                                <th>染色类型</th>
                            </tr>
                        </thead>
                        <tbody>
                            <!-- 纯视觉模型 -->
                            <tr class="category-header">
                                <td colspan="7">纯视觉模型</td>
                            </tr>
                            <tr>
                                <td>PathOrchestra</td>
                                <td>1024</td>
                                <td>300K</td>
                                <td>303M</td>
                                <td>ViT-L/16</td>
                                <td>DINOv2</td>
                                <td>H&E</td>
                            </tr>
                            <tr>
                                <td>UNI</td>
                                <td>1024</td>
                                <td>100K</td>
                                <td>303M</td>
                                <td>ViT-L/16</td>
                                <td>DINOv2</td>
                                <td>H&E</td>
                            </tr>
                            <tr>
                                <td>UNI2-h</td>
                                <td>1536</td>
                                <td>350K</td>
                                <td>681M</td>
                                <td>ViT-H/14</td>
                                <td>DINOv2</td>
                                <td>H&E, IHC</td>
                            </tr>
                            <tr>
                                <td>Virchow</td>
                                <td>1280</td>
                                <td>1.5M</td>
                                <td>631M</td>
                                <td>ViT-H/14</td>
                                <td>DINOv2</td>
                                <td>H&E</td>
                            </tr>
                            <tr>
                                <td>Virchow2</td>
                                <td>1280</td>
                                <td>3.1M</td>
                                <td>631M</td>
                                <td>ViT-H/14</td>
                                <td>DINOv2</td>
                                <td>H&E, IHC</td>
                            </tr>
                            <tr>
                                <td>Phikon</td>
                                <td>768</td>
                                <td>6K</td>
                                <td>86.4M</td>
                                <td>ViT-B/16</td>
                                <td>iBOT</td>
                                <td>H&E</td>
                            </tr>
                            <tr>
                                <td>Phikon-v2</td>
                                <td>1024</td>
                                <td>58K</td>
                                <td>303M</td>
                                <td>ViT-L/16</td>
                                <td>DINOv2</td>
                                <td>H&E, IHC</td>
                            </tr>
                            <tr>
                                <td>Prov-GigaPath</td>
                                <td>1536</td>
                                <td>171K</td>
                                <td>1.1B</td>
                                <td>ViT-G/14</td>
                                <td>DINOv2, MIM</td>
                                <td>H&E, IHC</td>
                            </tr>
                            <tr>
                                <td>H-Optimus-0</td>
                                <td>1536</td>
                                <td>500K</td>
                                <td>1.1B</td>
                                <td>ViT-G/14</td>
                                <td>iBOT, DINOv2</td>
                                <td>-</td>
                            </tr>
                            <tr>
                                <td>H-Optimus-1</td>
                                <td>1536</td>
                                <td>1M</td>
                                <td>1.1B</td>
                                <td>ViT-G/14</td>
                                <td>-</td>
                                <td>-</td>
                            </tr>
                            <tr>
                                <td>Midnight-12k</td>
                                <td>1536</td>
                                <td>12K</td>
                                <td>1.1B</td>
                                <td>ViT-G/14</td>
                                <td>DINOv2</td>
                                <td>H&E</td>
                            </tr>
                            <tr>
                                <td>Kaiko</td>
                                <td>1024</td>
                                <td>-</td>
                                <td>304M</td>
                                <td>ViT-L/14</td>
                                <td>DINOv2</td>
                                <td>H&E</td>
                            </tr>
                            <tr>
                                <td>Lunit</td>
                                <td>384</td>
                                <td>-</td>
                                <td>21.7M</td>
                                <td>ViT-S/8</td>
                                <td>DINO</td>
                                <td>H&E</td>
                            </tr>
                            <tr>
                                <td>Hibou</td>
                                <td>1024</td>
                                <td>1.1M</td>
                                <td>304M</td>
                                <td>ViT-L/14</td>
                                <td>DINOv2</td>
                                <td>H&E, others</td>
                            </tr>
                            <!-- 视觉-语言模型 -->
                            <tr class="category-header">
                                <td colspan="7">视觉-语言模型</td>
                            </tr>
                            <tr>
                                <td>CONCH</td>
                                <td>768</td>
                                <td>21K</td>
                                <td>90.4M</td>
                                <td>ViT-B/16</td>
                                <td>iBOT, CoCa</td>
                                <td>H&E, IHC</td>
                            </tr>
                            <tr>
                                <td>CONCHv1.5</td>
                                <td>1024</td>
                                <td>-</td>
                                <td>306M</td>
                                <td>ViT-L/16</td>
                                <td>CoCa</td>
                                <td>H&E, IHC</td>
                            </tr>
                            <tr>
                                <td>MUSK</td>
                                <td>1024</td>
                                <td>33K</td>
                                <td>675M</td>
                                <td>ViT-L/16</td>
                                <td>BEiT3</td>
                                <td>H&E</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>

            <!-- 微调策略 -->
            <div class="subsection">
                <h3 class="subsection-title">微调策略</h3>
                <p class="subsection-intro">
                    我们评估了五种不同的参数高效适配策略，以研究如何最有效地将PFM迁移到密集预测任务。
                </p>
                <div class="strategy-grid">
                    <div class="strategy-card">
                        <div class="strategy-header">
                            <span class="strategy-icon">❄️</span>
                            <h4>Frozen</h4>
                        </div>
                        <p>PFM编码器完全冻结，仅训练解码器和分割头。此设置以最少的可训练参数隔离预训练token表征的贡献。</p>
                    </div>
                    <div class="strategy-card">
                        <div class="strategy-header">
                            <span class="strategy-icon">🔧</span>
                            <h4>LoRA</h4>
                        </div>
                        <p>Low-Rank Adaptation：冻结编码器并将可训练的低秩适配器注入自注意力层。我们将LoRA应用于QKV和输出投影，仅优化低秩参数。</p>
                    </div>
                    <div class="strategy-card">
                        <div class="strategy-header">
                            <span class="strategy-icon">⚙️</span>
                            <h4>DoRA</h4>
                        </div>
                        <p>Weight-Decomposed Low-Rank Adaptation：通过可学习的幅度参数增强低秩适配，以解耦权重方向和尺度。</p>
                    </div>
                    <div class="strategy-card">
                        <div class="strategy-header">
                            <span class="strategy-icon">🧱</span>
                            <h4>CNN Adapter</h4>
                        </div>
                        <p>遵循TransUNet范式，将CNN空间先验与Transformer tokens融合。添加并行的ResNetV2风格CNN分支提取多尺度特征，并通过跳跃连接注入解码器。</p>
                    </div>
                    <div class="strategy-card">
                        <div class="strategy-header">
                            <span class="strategy-icon">🔄</span>
                            <h4>Transformer Adapter</h4>
                        </div>
                        <p>在冻结的PFM编码器后附加轻量级Transformer块堆栈，用于参数高效的任务特化。完整token序列由附加块处理，之后仅patch tokens转发到解码器。</p>
                    </div>
                </div>
                <div class="strategy-diagram-placeholder">
                    <p>微调策略示意图</p>
                    <small>Figure 2: 参数高效适配策略的示意图</small>
                </div>
            </div>
        </div>
    </section>

    <!-- 主要发现 -->
    <section id="findings" class="section section-alt">
        <div class="container">
            <h2 class="section-title">主要发现</h2>
            <p class="section-intro">
                我们的实验揭示了一个一致的叙事：虽然PFM提供了强大的通用特征，
                但朴素的缩放——无论是模型大小还是适配参数——都会产生递减回报。
                相反，密集预测的性能由token粒度、输入分辨率和架构归纳偏置之间的对齐驱动。
            </p>
            
            <div class="finding-cards">
                <div class="finding-card">
                    <div class="finding-number">01</div>
                    <h3>适配策略是决定性的</h3>
                    <p>
                        虽然"冻结"设置（仅训练解码器）提供了强大的起点，
                        但释放PFM的全部潜力需要有针对性的适配。
                        <strong>CNN Adapter经常成为表现最佳的策略</strong>，
                        特别是在CoNIC2022和CPM15等具有挑战性的细粒度任务中。
                    </p>
                    <div class="finding-insight">
                        <strong>洞察：</strong>通过卷积层注入局部归纳偏置可以有效补充Vision Transformers捕获的全局语义上下文。
                    </div>
                </div>
                
                <div class="finding-card">
                    <div class="finding-number">02</div>
                    <h3>模型规模不具有预测性</h3>
                    <p>
                        我们检验了模型大小（从21.7M到超过1B参数）与分割性能之间的关系。
                        <strong>分割性能与模型大小不呈单调关系</strong>。
                        较小或中等规模的模型通常能够匹配或超越明显更大的模型。
                    </p>
                    <div class="finding-insight">
                        <strong>解释：</strong>强调全局不变性的预训练目标可能在较大模型中诱导过度抽象，潜在地丢弃了边界划定所需的高频空间细节。
                    </div>
                </div>
                
                <div class="finding-card">
                    <div class="finding-number">03</div>
                    <h3>适配容量早期饱和</h3>
                    <p>
                        我们的LoRA秩消融研究揭示，增加LoRA秩不会产生一致的单调改进。
                        <strong>性能通常饱和或呈现轻微波动</strong>，
                        秩16和秩128之间的置信区间重叠。
                    </p>
                    <div class="finding-insight">
                        <strong>启示：</strong>适配PFM到分割的瓶颈不是适配器的容量，而是冻结表征的内在结构。中等秩提供了有利的精度-效率权衡。
                    </div>
                </div>
                
                <div class="finding-card">
                    <div class="finding-number">04</div>
                    <h3>输入分辨率是真正的驱动因素</h3>
                    <p>
                        我们观察到对输入分辨率的明显依赖。将输入尺寸从256增加到1024产生显著增益，
                        <strong>mDice在1024×1024达到峰值</strong>。
                        然而，进一步推高分辨率到2048或4096并不能提高性能，甚至可能导致轻微下降。
                    </p>
                    <div class="finding-insight">
                        <strong>结论：</strong>在低分辨率下，patch tokens聚合了太多不同的形态内容；在过高分辨率下，表征碎片化为过于局部的亚细胞模式。存在一个最佳分辨率"甜点"。
                    </div>
                </div>
            </div>

            <div class="key-message">
                <div class="key-message-icon">💡</div>
                <div class="key-message-content">
                    <h4>核心结论</h4>
                    <p>
                        将病理基础模型迁移到密集预测不是"更多规模"的问题，而是<strong>表征对齐</strong>的问题。
                        成功取决于：(i) 选择注入保持局部性归纳偏置的架构（如CNN适配器）；
                        (ii) 选择能够保持形态完整性同时维持连贯空间上下文的输入分辨率。
                    </p>
                </div>
            </div>
        </div>
    </section>

    <!-- 实验结果 -->
    <section id="results" class="section">
        <div class="container">
            <h2 class="section-title">实验结果</h2>
            
            <div class="results-overview">
                <div class="result-figure-placeholder">
                    <p>性能对比图</p>
                    <small>Figure 3: 不同微调策略和数据集上的分割性能</small>
                </div>
            </div>

            <div class="result-tables">
                <h3 class="subsection-title">分割性能汇总</h3>
                <p class="subsection-intro">
                    以下展示了不同PFM在各数据集上的mDice性能。表格数据将在后续填充。
                </p>
                
                <!-- Frozen性能表格 -->
                <div class="table-container">
                    <h4 class="table-title">表 C1. BCSS数据集上的Frozen PFM分割性能</h4>
                    <p class="table-desc">均值及95%置信区间</p>
                    <table class="data-table result-table">
                        <thead>
                            <tr>
                                <th>模型</th>
                                <th>mIoU</th>
                                <th>Pixel Acc</th>
                                <th>mAcc</th>
                                <th>FW IoU</th>
                                <th>mDice</th>
                                <th>mPrecision</th>
                                <th>mRecall</th>
                                <th>mF1</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>PathOrchestra</td>
                                <td>0.221</td>
                                <td>0.663</td>
                                <td>0.313</td>
                                <td>0.489</td>
                                <td>0.295</td>
                                <td>0.528</td>
                                <td>0.313</td>
                                <td>0.569</td>
                            </tr>
                            <tr>
                                <td>UNI</td>
                                <td>0.247</td>
                                <td>0.674</td>
                                <td>0.356</td>
                                <td>0.526</td>
                                <td>0.328</td>
                                <td>0.548</td>
                                <td>0.356</td>
                                <td>0.554</td>
                            </tr>
                            <tr>
                                <td>Virchow2</td>
                                <td>0.251</td>
                                <td>0.682</td>
                                <td>0.369</td>
                                <td>0.532</td>
                                <td>0.332</td>
                                <td>0.542</td>
                                <td>0.369</td>
                                <td>0.561</td>
                            </tr>
                            <!-- 更多数据行将在后续添加 -->
                            <tr class="placeholder-row">
                                <td colspan="9" class="placeholder-cell">更多模型数据待添加...</td>
                            </tr>
                        </tbody>
                    </table>
                </div>

                <!-- 缩放行为热力图占位符 -->
                <div class="result-figure-placeholder large">
                    <p>缩放行为热力图</p>
                    <small>Figure 4: Frozen方法下病理基础模型的缩放行为 - 模型参数量 vs 数据集 vs mDice分数</small>
                </div>

                <!-- LoRA秩消融图占位符 -->
                <div class="result-figure-placeholder">
                    <p>LoRA秩消融实验</p>
                    <small>Figure 5: 代表性病理分割任务上不同LoRA秩的消融实验（带95%置信区间）</small>
                </div>
            </div>
        </div>
    </section>

    <!-- 附录 -->
    <section id="appendix" class="section section-alt">
        <div class="container">
            <h2 class="section-title">附录</h2>
            <p class="section-intro">
                完整的实验结果表格，包括所有17个PFM在18个数据集上使用5种微调策略的详细性能指标。
            </p>

            <!-- 附录导航 -->
            <div class="appendix-nav">
                <button class="appendix-tab active" data-tab="frozen">Frozen</button>
                <button class="appendix-tab" data-tab="lora">LoRA</button>
                <button class="appendix-tab" data-tab="dora">DoRA</button>
                <button class="appendix-tab" data-tab="cnn">CNN Adapter</button>
                <button class="appendix-tab" data-tab="trans">Transformer Adapter</button>
            </div>

            <!-- Frozen表格 -->
            <div id="frozen-tables" class="appendix-content active">
                <h3>Frozen PFM 性能结果</h3>
                
                <!-- 各数据集表格占位符 -->
                <div class="table-group">
                    <div class="table-container collapsible">
                        <h4 class="table-title collapsible-header">
                            表 C1. BCSS - Frozen PFM 分割性能
                            <span class="collapse-icon">▼</span>
                        </h4>
                        <div class="collapsible-content">
                            <table class="data-table appendix-table">
                                <thead>
                                    <tr>
                                        <th>模型</th>
                                        <th>mIoU</th>
                                        <th>mDice</th>
                                        <th>mPrecision</th>
                                        <th>mRecall</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr class="placeholder-row">
                                        <td colspan="5" class="placeholder-cell">数据待填充...</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                    </div>

                    <div class="table-container collapsible">
                        <h4 class="table-title collapsible-header">
                            表 C2. COSAS24 - Frozen PFM 分割性能
                            <span class="collapse-icon">▼</span>
                        </h4>
                        <div class="collapsible-content">
                            <table class="data-table appendix-table">
                                <thead>
                                    <tr>
                                        <th>模型</th>
                                        <th>mIoU</th>
                                        <th>mDice</th>
                                        <th>mPrecision</th>
                                        <th>mRecall</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr class="placeholder-row">
                                        <td colspan="5" class="placeholder-cell">数据待填充...</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                    </div>

                    <div class="table-container collapsible">
                        <h4 class="table-title collapsible-header">
                            表 C3. CRAG - Frozen PFM 分割性能
                            <span class="collapse-icon">▼</span>
                        </h4>
                        <div class="collapsible-content">
                            <table class="data-table appendix-table">
                                <thead>
                                    <tr>
                                        <th>模型</th>
                                        <th>mIoU</th>
                                        <th>mDice</th>
                                        <th>mPrecision</th>
                                        <th>mRecall</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr class="placeholder-row">
                                        <td colspan="5" class="placeholder-cell">数据待填充...</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                    </div>

                    <!-- 其他数据集表格占位符 -->
                    <div class="more-tables-placeholder">
                        <p>更多数据集表格（CoNIC2022, CoNSeP, CPM15, CPM17, EBHI, GlaS, Janowczyk, Kumar, Lizard, NuCLS, PanNuke, RINGS, TNBC, WSSS4LUAD, CoCaHis）将在此处添加...</p>
                    </div>
                </div>
            </div>

            <!-- LoRA表格占位符 -->
            <div id="lora-tables" class="appendix-content">
                <h3>LoRA 微调性能结果</h3>
                <div class="more-tables-placeholder">
                    <p>LoRA微调策略下的所有数据集性能表格将在此处添加...</p>
                </div>
            </div>

            <!-- DoRA表格占位符 -->
            <div id="dora-tables" class="appendix-content">
                <h3>DoRA 微调性能结果</h3>
                <div class="more-tables-placeholder">
                    <p>DoRA微调策略下的所有数据集性能表格将在此处添加...</p>
                </div>
            </div>

            <!-- CNN Adapter表格占位符 -->
            <div id="cnn-tables" class="appendix-content">
                <h3>CNN Adapter 微调性能结果</h3>
                <div class="more-tables-placeholder">
                    <p>CNN Adapter微调策略下的所有数据集性能表格将在此处添加...</p>
                </div>
            </div>

            <!-- Transformer Adapter表格占位符 -->
            <div id="trans-tables" class="appendix-content">
                <h3>Transformer Adapter 微调性能结果</h3>
                <div class="more-tables-placeholder">
                    <p>Transformer Adapter微调策略下的所有数据集性能表格将在此处添加...</p>
                </div>
            </div>
        </div>
    </section>

    <!-- 引用 -->
    <section id="citation" class="section">
        <div class="container">
            <h2 class="section-title">引用</h2>
            <div class="citation-box">
                <pre><code>@inproceedings{chen2025pfmdensebench,
  title={To What Extent Do Token-Level Representations from Pathology Foundation Models Improve Dense Prediction?},
  author={Chen, Weiming and Ling, Xitong and Wang, Xidong and Cai, Zhenyang and Guo, Yijia and Fu, Mingxi and Zeng, Ziyi and Ouyang, Minxi and Li, Jiawen and Wang, Yizhi and Guan, Tian and Wang, Benyou and He, Yonghong},
  booktitle={Proceedings of the 42nd International Conference on Machine Learning},
  year={2025}
}</code></pre>
                <button class="copy-btn" onclick="copyToClipboard()">复制</button>
            </div>
        </div>
    </section>

    <!-- 页脚 -->
    <footer class="footer">
        <div class="container">
            <div class="footer-content">
                <div class="footer-logo">
                    <h3>PFM-DenseBench</h3>
                    <p>病理基础模型密集预测基准测试</p>
                </div>
                <div class="footer-links">
                    <div class="footer-column">
                        <h4>资源</h4>
                        <ul>
                            <li><a href="#">论文 PDF</a></li>
                            <li><a href="#">代码仓库</a></li>
                            <li><a href="#">数据集</a></li>
                            <li><a href="#">模型权重</a></li>
                        </ul>
                    </div>
                    <div class="footer-column">
                        <h4>联系</h4>
                        <ul>
                            <li><a href="mailto:heyh@sz.tsinghua.edu.cn">何永红</a></li>
                            <li><a href="mailto:wangbenyou@cuhk.edu.cn">王本友</a></li>
                        </ul>
                    </div>
                </div>
            </div>
            <div class="footer-bottom">
                <p>&copy; 2025 PFM-DenseBench. ICML 2025.</p>
            </div>
        </div>
    </footer>

    <script src="script.js"></script>
</body>
</html>
